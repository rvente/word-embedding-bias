\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{origins-1810-03611}
\citation{lison2017redefining}
\citation{lison2017redefining}
\citation{lison2017redefining}
\citation{mikolov2013exploiting}
\citation{mikolov2013exploiting}
\citation{mikolov2013exploiting}
\citation{mikolov2013exploiting}
\citation{mikolov2013exploiting}
\citation{biased_analogy-1607-06520}
\citation{origins-1810-03611}
\citation{caliskan2017semantics}
\citation{biased_analogy-1607-06520}
\citation{lipstick-1903-03862}
\citation{biased_analogy-1607-06520}
\citation{zhao2018learning}
\citation{lipstick-1903-03862}
\citation{lipstick-1903-03862}
\citation{lipstick-1903-03862}
\citation{caliskan2017semantics}
\citation{weat-1608-07187}
\citation{weat-1608-07187}
\citation{weat-1608-07187}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{weatxwindow}{{3}{3}{This comparison between 2010 and 2021 Wikipedia Embeddings shows that they behave roughly the same: up to a point, larger window sizes produce embedding models with higher WEAT scores. It does not suggest that one year's data is any more biased than another's: learned gender bias in Wikipedia as measured by WEAT persists with time, however window size increases bias as measured by WEAT\relax }{figure.caption.3}{}}
\citation{rehurek_lrec}
\citation{clark2013handbook}
\citation{Wikiextractor2014}
\citation{agirre2009study}
\citation{mikolov2013distributed}
\newlabel{perf21}{{4}{4}{The Analogy task (above) peaks early for Word2Vec, yielding a negative correlation with window size as more ``distracting'' words are introduced into the context window. FastText does not exhibit this property increasing before a plateau. Word Similarity (below) also responds positively with window size, also with diminishing returns as window sizes get large. \relax }{figure.caption.4}{}}
\bibstyle{acl_natbib}
\bibdata{arr}
\bibcite{agirre2009study}{{1}{2009}{{Agirre et~al.}}{{Agirre, Alfonseca, Hall, Kravalova, Pasca, and Soroa}}}
\bibcite{Wikiextractor2014}{{2}{2014}{{Attardi}}{{}}}
\bibcite{biased_analogy-1607-06520}{{3}{2016}{{Bolukbasi et~al.}}{{Bolukbasi, Chang, Zou, Saligrama, and Kalai}}}
\newlabel{biasxperf}{{5}{5}{This is the scatter plot of Career-Family WEAT score against Analogy accuracy (above) and Word Similarity (below) this positive correlation suggests that models that have higer WEAT scores end to be the ones that perform better on convention benchmarks as well. \relax }{figure.caption.5}{}}
\bibcite{origins-1810-03611}{{4}{2018}{{Brunet et~al.}}{{Brunet, Alkalay{-}Houlihan, Anderson, and Zemel}}}
\bibcite{caliskan2017semantics}{{5}{2017}{{Caliskan et~al.}}{{Caliskan, Bryson, and Narayanan}}}
\bibcite{clark2013handbook}{{6}{2013}{{Clark et~al.}}{{Clark, Fox, and Lappin}}}
\bibcite{lipstick-1903-03862}{{7}{2019}{{Gonen and Goldberg}}{{}}}
\bibcite{weat-1608-07187}{{8}{2016}{{Islam et~al.}}{{Islam, Bryson, and Narayanan}}}
\bibcite{lison2017redefining}{{9}{2017}{{Lison and Kutuzov}}{{}}}
\bibcite{mikolov2013exploiting}{{10}{2013{a}}{{Mikolov et~al.}}{{Mikolov, Le, and Sutskever}}}
\bibcite{mikolov2013distributed}{{11}{2013{b}}{{Mikolov et~al.}}{{Mikolov, Sutskever, Chen, Corrado, and Dean}}}
\bibcite{rehurek_lrec}{{12}{2010}{{{\v R}eh{\r u}{\v r}ek and Sojka}}{{}}}
\bibcite{zhao2018learning}{{13}{2018}{{Zhao et~al.}}{{Zhao, Zhou, Li, Wang, and Chang}}}
